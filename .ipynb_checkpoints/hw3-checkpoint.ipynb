{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open('reviews_Movies_and_TV_5.json') as json_file: \n",
    "    for rec in json_file:\n",
    "        dic = json.loads(rec)\n",
    "        reviews.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 500,000 records for faster computation\n",
    "random.seed(123)\n",
    "random.shuffle(reviews)\n",
    "reviews = reviews[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev in reviews:\n",
    "    review.append(rev['reviewText'])\n",
    "    label.append(rev['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame({\"review\":review, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents is 500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents is %s\"%len(review_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels is 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of labels is %s\"%len(review_df.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution is as follows: \n",
      "   label  review  proportion\n",
      "0    1.0   30757    0.061514\n",
      "1    2.0   30068    0.060136\n",
      "2    3.0   59488    0.118976\n",
      "3    4.0  113145    0.226290\n",
      "4    5.0  266381    0.532762\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution is as follows: \")\n",
    "distribution = review_df.groupby('label')['review'].nunique().reset_index()\n",
    "distribution['proportion'] = distribution['review'] / len(review_df)\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length in a review is 164.213994\n"
     ]
    }
   ],
   "source": [
    "print(\"Average word length in a review is %s\"%(np.mean([len(text.split(' ')) for text in review_df['review']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(text):\n",
    "    clean_rev = [w.lower() for w in word_tokenize(text) if w not in stop_words and w.isalpha()]\n",
    "    return ' '.join(clean_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rev = [process_review(i) for i in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = multiprocessing.Pool(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pool.map(process_review, rev_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['cleaned_review'] = clean_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not the best Hutton/Prentiss movie by far but ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>not best movie far okay i prefer where the boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a good series for toddlers-- we have m...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this good series toddlers entire dvd overcomin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought this for the wife. I did like this se...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>i bought wife i like series watched wife the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the 1950's,  Tv was live. It was theater in...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>in tv live it theater video format the idea vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let me begin by saying that the movie itself d...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>let begin saying movie deserves stars having s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  Not the best Hutton/Prentiss movie by far but ...    3.0   \n",
       "1  This is a good series for toddlers-- we have m...    5.0   \n",
       "2  I bought this for the wife. I did like this se...    2.0   \n",
       "3  In the 1950's,  Tv was live. It was theater in...    5.0   \n",
       "4  Let me begin by saying that the movie itself d...    3.0   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  not best movie far okay i prefer where the boy...  \n",
       "1  this good series toddlers entire dvd overcomin...  \n",
       "2  i bought wife i like series watched wife the s...  \n",
       "3  in tv live it theater video format the idea vi...  \n",
       "4  let begin saying movie deserves stars having s...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(review_df[['cleaned_review', 'label']].dropna(), random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['cleaned_review'].values\n",
    "train_y = train['label'].values\n",
    "test_x = test['cleaned_review'].values\n",
    "test_y = test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train, test, max_df=0.95, ngram=(1,1)):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=max_df, ngram_range=ngram)\n",
    "    tfidf_vectorizer.fit_transform(train)\n",
    "    train_feature = tfidf_vectorizer.transform(train)\n",
    "    test_feature = tfidf_vectorizer.transform(test)\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf, test_x_tfidf = tf_idf(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "lr_1gram = LogisticRegression(solver='liblinear', random_state=123, C=5, penalty='l1', max_iter=100)\n",
    "model = lr_1gram.fit(train_x_tfidf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(test_y, pred)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n",
    "f1 = 2*recall*precision/(recall+precision)\n",
    "\n",
    "(unique, counts) = np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-recall is: 0.613504\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro-recall is: %s\"%(sum(counts*recall)/sum(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-precision is 0.5763339536759488\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro-precision is %s\"%(sum(counts*precision)/sum(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-F1 score is 0.5861154517932219\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro-F1 score is %s\"%(sum(counts*f1)/sum(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy is 0.613504\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy is %s\"%(sum(pred==test_y)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
